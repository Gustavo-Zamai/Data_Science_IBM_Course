‚òÅÔ∏è Cloud Computing, Deployment and Service Models
--

#### Define cloud deployment models and service models:

- Deployments:
    
    - Public - use is shared by other companies;
    - Private - infrastructure is provisioned for exclusive use by a single organization
    - Hibridy - mix of public and private

- Models:

    - IaaS (Infrastucture) - delivery data centers, servers, networking and storage;
    - Paas (Plataform) - hardware and software tools to develop and deploy applications to users over the internet; 
    - Saas (Service) - software and application are license and hosted on a subscription basis 

#### Identify characteristics of cloud computing:

- On-demand self-service;
- Network access - trough mobile, desktops and laptops;
- Resource pooling - cost efficient;
- Elasticity - use what you need, increase or decrease, depends on costumers demand;
- Measured service - pay for waht you use, or reserve to go;
- Is about to using technology as a service, increase or decrease and pay for waht you use;
- Change the way consumes compute services.

### Cloud for Data Science:
- Work with multiple people from different places, countries at the same time;
- Bypass phisical limitations, to storage or run algorithms.
---

üé≤ Foundations of Big Data
--

- V's of big data:
    - Velocity: data is being created and accumulated extremelly fast, in different devices;
    - Volume: increase the data stored volume
    - Variety: different type of data, structure or unstructure, also comes from different sources;
    - Veracity: quality and origin of data
    - Value: turn data into value

---

üß∞ Big Data Processing Tools:
--

- Apache hadoop:
    - distributed storage and processing of big data;
    - no format requeirements for storing data;
    - scalable and reliable storage;
    - HDFS allowing parallel access to data across different nodes, clusters;
    - HDFS built to detect faults and automatically recover;
    - compability with a large variety of operating systems;

- Apache Hive:
    - data warehouse for data query and analysis;
    - based on hadoop, stored dataset files in HDFS;
    - suited for ETL, reporting and analysis;
    - easy access to data via SQL;

- Apache Spark:
    - analytics framework for complex and real-time data analytics;
    - ML, data integration and ETL;
    - acces data in a large variety of data sources;
    - in-memory processing to increase speed of computations;
    - processes streaming data fast.
---

‚õèÔ∏è Data Mining:
--

- Goal set: identify key questions;
- Select data: identify data sources; 
- Preprocess: clean the data; 
- Transform: determine storage needs;
- Data mine: determine methods, ML, and analyze;
- Evaluate: assess outcomes, the efficienty of the algorithm and share results.
